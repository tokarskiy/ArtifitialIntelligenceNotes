\input{preamble}
\usepackage[utf8]{inputenc}
\title{Конспект по исскуственному интеллекту}

\begin{document}
    \maketitle
    \clearpage
    \tableofcontents    
    \clearpage
    
    \section{Теория нечётких множеств}
        Степень достоверности - уровень принадлежности к классу по характеристикам
		
		Нечетким множеством $\tilde A$ на универсальном множестве $X$ называется совокупность пар
		$(x, \mu_{\tilde A}(x))$, где $\mu_{\tilde A}(x)$
		- степень принадлежности элемента $x$ из
		$X$ множеству $\widetilde{A}$.
		
		
		Элементы с нулевой степенью принадлежности не включаются в множество.
		
		Деффазификацией называется процедура преобразования нечеткого множества в четкое число.
		(четкое множество). Физически процедура похожа на поиск центра масс. 
		
		Высотой нечеткого множества $\tilde A$ 
		\[h(\tilde A) = sup(\mu_{\tilde A}(x))\]
		\[h(\tilde A) = max(\mu_{\tilde A}(x))\]
		
		
    
        $\tilde A =$ "небольшое натуральное число"
		\[\tilde A = {(1, 1), (2, 1), (3, 0.9), (4, 0.8), (5, 0.6), (6, 0.5), (7, 0.4), (8. 0.2), (9, 0)}\]
		
		$\tilde B =$ "натуральное число, приближённо равное 2"
		\[\tilde B = {(1, 0.5), (2, 1), (3, 0.6), (4, 0.4), (5, 0.2), (6, 0), ... (9, 0)}\]
		
		\subsection{Пересечение}
    		Пересечением двух нечетких множеств А и В, заданных на одном универсуме Х, является 
			нечеткое множество С, заданном на том же универсуме Х, функция принадлежности которого
			вычисляется
			
			Обозначается $\tilde A \cap \tilde B$
			
			\[\mu_{\tilde A \cap \tilde B}(x) = min(\mu_{\tilde A}(x), \mu_{\tilde B}(x))\]
			
			Пример
			
				\[\tilde C = \tilde A \cap \tilde B = \{(1, 0.5), (2, 1), (3, 0.6), (4, 0.4), (5, 0.2), (6, 0) ...\}\]
				
				$\tilde C$ = "небольшое нат. число, приближённо равное 2"
			
		\subsection{Дополнения}
		    Дополнением $\tilde A$ на $X$ называется множество $\tilde A'$ , функция принадлежности элементов 
		    которого вычисляется как $\mu_{\tilde A'}(x) = 1 - \mu_{\tilde A}(x)$
		
			$\tilde A$ = "натуральное число, не являющееся небольшим"
			
			$\tilde A'$ = "нат. число, не являющееся приближенно равным 2"
		\subsection{Объединение}
		    Обозначается $\tilde A \cup \tilde B$
		
			\[\mu_{\tilde A \cup \tilde B}(x) = max(\mu_{\tilde A}(x), \mu_{\tilde B}(x))\]
			
			Пример
				\[\tilde C = \tilde A \cup \tilde B = \{(1, 1), (2, 1), (3, 0.9), (4, 0.8), (5, 0.6), (6, 0.5), (7, 0.4), (8, 0.2), (9, 0)\}\]
				
				$\tilde C$ = "или небольшое натуральное число, или число, приближенно равное 2"
				
		\subsection{Разность нечетких множеств}
		    Обозначается $\tilde A \backslash \tilde B$
		
			\[\mu_{\tilde A \backslash \tilde B}(x) = max(\mu_{\tilde A}(x) -  \mu_{\tilde B}(x), 0)\]
			
			Пример
			\[\tilde C = \tilde A \backslash \tilde B = \{(1, 0.5), (2, 0), (3, 0.3), (4, 0.4), (5, 0.4), (6, 0.5), (7, 0.4), (8, 0.2), (9, 0)\}\]
			
			$\tilde C$ = "небольшое нат. число, не являющееся приближенно равным 2"
			
			\[\tilde C = B \backslash \tilde A = \{(1, 0), \dots, (9, 0)\}\]
			
			$\tilde C$ = "приближенно равное 2 нат. число, не являющееся небольшим"
			
		\subsection{Симметрическая разность} 
		    Обозначается $\tilde A \ominus \tilde B$
			\[\mu_{\tilde A \ominus \tilde B}(x) = \|\mu_{\tilde A}(x) - \mu_{\tilde B}(x)\|\]
			
		\subsection{Алгебраическое объединение (алгебраическая сумма)}
		    Обозначается $\tilde A + \tilde B$
		
	        \[\mu_{\tilde A + \tilde B}(x) = \mu_{\tilde A}(x) + \mu_{\tilde B}(x) - \mu_{\tilde A}(x) \cdot \mu_{\tilde B}(x)\]
		    
			\[\tilde C = \tilde A + \tilde B = \{(1, 1), (2, 1), (3, 0.96), (4, 0.88), \dots\}\]
			
		\subsection{Алгебраическое пересечение}
		    Обозначается $\tilde A \cdot \tilde B$
		
			\[\mu_{\tilde A \cdot \tilde B}(x) = \mu_{\tilde A}(x) \cdot \mu_{\tilde B}(x)\]
			
			\[\tilde C = \tilde A \cdot \tilde B = \{(1, 0.5), (2, 1), (3, 0.54), (4, 0.32), \dots\}\]
			
		\subsection{Граничное пересечение} 
		    Обозначается $\tilde A \otimes \tilde B$
		    
		    \[\mu_{\tilde A \otimes \tilde B}(x) = max(\mu_{\tilde A}(x) + \mu_{\tilde B}(x) - 1, 0)\]
			
			\[\tilde C = \tilde A \otimes \tilde B = \{(1, 0.5), (2, 1), (3, 0.5), (4, 0.2), (5, 0), \dots\}\]
			
		\subsection{Граничное объединение}
		    Обозначается $\tilde A \oplus \tilde B$
		
			\[\mu_{\tilde A \oplus \tilde B}(x) = min(\mu_{\tilde A}(x) + \mu_{\tilde B}(x), 1)\]
			
			\[\tilde C = \tilde A \oplus \tilde B = \{(1, 1), (2, 1), (3, 1), (4, 1), (5, 0.8), (6, 0.5) ...\}\]
			
		\subsection{Драстическое пересечение}
		    Обозначается $\tilde A \Delta \tilde B$
		
			\begin{equation}
                \begin{matrix}
                \mu_{\tilde A \Delta \tilde B}(x) & =
                & \left\{
                \begin{matrix}
                \mu_{\tilde B}(x) & \mbox{if } \mu_{\tilde A }(x) = 1\\
                \mu_{\tilde A}(x) & \mbox{if } \mu_{\tilde B }(x) = 1\\
                0 & \mbox{otherwise }
                \end{matrix} \right.
                \end{matrix}
            \end{equation}
			
			\[\tilde C = \tilde A \Delta \tilde B = \{(1, 0.5), (2, 0) ...\}\]
		
		\subsection{Драстическое объединение}
		    Обозначается $\tilde A \nabla \tilde B$
		
			\begin{equation}
                \begin{matrix}
                \mu_{\tilde A \nabla \tilde B}(x) & =
                & \left\{
                \begin{matrix}
                \mu_{\tilde B}(x) & \mbox{if } \mu_{\tilde A }(x) = 0\\
                \mu_{\tilde A}(x) & \mbox{if } \mu_{\tilde B }(x) = 0\\
                1 & \mbox{otherwise }
                \end{matrix} \right.
                \end{matrix}
            \end{equation}
			
		\subsection{Ядро нечеткого множества}
			Ядро нечеткого множество - четкое множество элементов, для которых функция принадлежности
			равно $1$.
			
		\subsection{Граница нечеткого множества}
			Это элементы, для которых значения функции принадлежности отличны от $0$ или $1$. В разных
			задачах, границы могут иметь разный диапазон.
			
		\subsection{Точки перехода}
			Это элементы, когда функция принадлежности приближенно равна 0.5
		
		\subsection{Умножение нечеткого множества на число}
			Тогда функция принадлежности 
			\begin{equation}
                \begin{matrix}
                \mu_{c \cdot \tilde A}(x) & =
                & \left\{
                \begin{matrix}
                c \cdot \mu_{\tilde A}(x) & \mbox{if } c \cdot \mu_{\tilde A}(x) < 1\\
                1 & \mbox{otherwise }
                \end{matrix} \right.
                \end{matrix}
            \end{equation}
				
		\subsection{Концентрирование} 
			\[\mu_{\tilde A_C}(x) = \mu_{\tilde A}(x)^2\]
			
			По-сути, операция отсекает сомнительные края
			
		\subsection{Растяжение (размытие)}
			\[\mu_{\tilde A_R}(x) = \sqrt{\mu_{\tilde A}(x)}\]
			
		\subsection{Дизьюнктивная сумма}
			\[\mu_{\tilde C}(x) = max(min(\mu_{\tilde A}(x), 1 - \mu_{\tilde B}(x)), min(1 - \mu_{\tilde A}(x), \mu_{\tilde B}(x)))\]
			\[C = (\tilde A \cap \tilde B') \cup (\tilde A' \cap \tilde B)\]
			
			\[\tilde C = \{(1, 0.5), ...\}\]
	\section{Нейронные сети}
	    \subsection{Биологический нейрон}
		    Биологический нейрон состоит из
    		\begin{itemize}
    		    \item Тело клетки (сома)
    				Содержит ядро с информацией и свойствами нейрона и плазмы (питание). 
    			\item Ответвления двух видов
    			    \begin{itemize}
    			        \item Аксон (как правило, один)
    				    \item Дендриты (много)
    			    \end{itemize}
    			    Нейрон принимает сигнал через дендриты и передаёт через аксон. 
    			    Синапс - точка контакта между аксонами одного нейрона и дендритами другого.
    		\end{itemize}
		
		\subsection{Компоненты исскусственного нейрона}
		    \begin{figure}[h!]
                \centering
                \includegraphics[scale=0.75]{Materials/b.png}
                \caption{Структура исскуственного нейрона}
            \end{figure}
    		\begin{itemize}
    		        \item Весовые коэффициенты - $w_1, w_2 \dots w_n$
    				Каждый вход $x_i$ имеет свой синапсический вес $w_i$, который является мерой
    				важности входных связей. Весы влиятельного входа усиливаются, несущественного 
    				входа принудительно уменьшаются. В природе макчимальный вес, например, имеют сенсорные 
    				нейроны. Весы могут изменяться в соответствии с обучающими примерами, архитектурой сети 
    				и правилами обучения. 
    			    \item Блок суммирования
    				Функция сумматора. Первоначально, первое действие нейрона - рассчет взвешенной суммы, результатом
    				которой является одно число. Расширением функции-сумматора являются любые другие операции (min, max,
    				avg, or, and и.т.д.). Также, входные сигналы и весовые коэффициенты перед поступлением в передаточную 
    				функцию могут комбинироваться разными способами, что определяется архитектурой сети и видом правила
    				обучения.  Иногда к функции сумматора добавляют функцию активации, которыя смещает выход функции сумматора 
    				по времени. 
    			    Передаточная функция 
    				Определяет зависимость сигнала на выходе нейрона от взвешенной суммы на его входах.
    				
    				Основные типы передаточных функций
    				\begin{itemize}
    				\item Линейная
    					\begin{equation}
                            \begin{matrix}
                            F(x) & =
                            & \left\{
                            \begin{matrix}
                            0 & \mbox{if } x < -0.5\\
                            1 & \mbox{if } x > 0.5\\
                            x + 0.5 & \mbox{otherwise }
                            \end{matrix} \right.
                            \end{matrix}
                        \end{equation}
                        
    					Линейная с насыщением
    						
    					\begin{equation}
                            \begin{matrix}
                            F(x) & =
                            & \left\{
                            \begin{matrix}
                            0 & \mbox{if } x < 0\\
                            1 & \mbox{if } x > 1\\
                            x & \mbox{otherwise }
                            \end{matrix} \right.
                            \end{matrix}
                        \end{equation}
                        
                        В исскуственных нейросетях передаточные функции такого типа составляют входной слой.
    					Недостаток - не является дифференцируемой по $x$ на всему множеству $\mathds{R}$, и не может быть использована 
    					в некоторых обучениях.
    				\item Пороговая (функция Хевисайда)
    				
    					\begin{equation}
                            \begin{matrix}
                            F(x) & =
                            & \left\{
                            \begin{matrix}
                            0 & \mbox{if } x < T\\
                            1 & \mbox{otherwise }
                            \end{matrix} \right.
                            \end{matrix}
                        \end{equation}
    					\[T = - w_0 \cdot x_0\]
    					
    					Представляет собой перепад до тех пор. Пока взвешенный сигнал на входе нейронов не достигнет 
    					уровня Т, сигнал на выходе = 0, как только достигнет - сигнал скачкообразно меняется на 1.
    				\item Сигмоидальная функция
    					\[F(x) = \frac{1}{1 + e^{-t \cdot x}}\]
    					S-образная кривая, приближает минимальное и максимальное значения в асимптотах. Называется сигмоидом, 
    					если $y \in (0, 1)$, или гиперболический тангенсом, если $y \in (-1, 1)$.
    					Использование сигмоидальных функций позволило перейти от бинарных выходов нейрона к аналоговым. 
    					Функции передачи такого типа используются нейронами, находящимися во внутренних слоях нейросети.
    				\end{itemize}
    			    \item Масштабирование 
    				После передаточной функции выходной сигнал множится на масштабирующий коэффициент. Не обязательный элемент.
    			    \item Выходная функция(соревнование)
    				В некоторых сетевых архитектурах результаты передаточной функции изменяются для создания соревнования 
    				между соседними нейронами. Нейронам разрешается соревноваться, блокируя действия слабых нейронов. Соревнование 
    				может быть на одном или на разных уровнях (слоях). Конкуренция определяет, какой нейрон обеспечит выходной
    				сигнал и какой нейрон примет участие в процессе обучения. 
    			    \item Функция погрешности и распрастраняемое назад значение. 
    				В большинстве обучаемых сетей вычислиется разность между полученным и желаемым выходами. Грубо говоря, это
    				погрешность. Поточная погрешность распространятся назад к предыдущему слою, и это значение учитывается в 
    				следующем цикле обучения. 
    			    \item Функция обучения 
    				Контролируемое обучение максимально распростаненное. Текущий вход постоянно сравнивается с желаемым выходом. 
    				Весы в начале устанавливаются случайно, но в последующих итерациях корректируются, чтобы была минимальная 
    				погрешность. 
    				Перед использованием, нейросеть с контролируемым обучением всегда должна обучиться (процесс обучения может занять несколько часов).
    				
    				Типы правил обучения:
    				    \begin{itemize}
    				        \item Коррекция по ошибке
    					    \item Обучение Больцмана
    					    \item Правило Хебба
    						    Если нейроны с обеих сторон синапса активизируются одновременно и регулярно, сила синапсичесной связи 
    						возростает. 
    					    \item Обучение методом соревнования
    				    \end{itemize}
    		\end{itemize}
					
		\subsection{Архитектура нейросети}
			Бывают слабосвязные нейросети и полносвязные (каждый нейрон связан с каждым). Они комбинируются.
			Чаще всего встречаются многослойные сети.
            \begin{figure}[h]
            \begin{minipage}[h]{0.49\linewidth}
            \center{\includegraphics[width=0.5\linewidth]{Materials/c.png} \\ а)}
            \end{minipage}
            \hfill
            \begin{minipage}[h]{0.49\linewidth}
            \center{\includegraphics[width=0.5\linewidth]{Materials/d.png} \\ б)}
            \end{minipage}
            \caption{Слабосвязная (а) и многослойная (б) нейросети.}
            \label{ris:image1}
            \end{figure}
    \section{Распознавание образов}
        
        
        \subsection{Фаза функционирования}
        Фаза функционирования бывает двух типов:
            \subsubsection{Обучение с учителем}
            
                Отнесение предъявляемых объектов к определённым классам с применением правил классификации. Перед этим система обучается на множестве примеров, самонастраиваясь.
                
                Набор образцовых объектов называют \textbf{обучающей выборкой}. Необученная система распознаёт предполагаемые объекты с сравнивает свои ответы с правильными ответами учителя и корректирует параметры решающего правила. При использовании метода перечисления 
                для задания класса система сохраняет в памяти всю доступную об объекте информацию. Если классы задаются описанием общих свойств, система определяет различия в значениях признаков объектов разных классов. При кластерном подходе формируются исходные кластеры в пространстве признаков. Обучающая выборка представляет собой таблицу, строки которой - названия объектов ($\omega_i$), а столбцы - названия признаков ($X_i$). Строки таблицы сгрупированы по классам $K_1 \dots K_m$.
                
                \begin{longtable}{|c|c|c|c|c|c|}
        		\hline
        		\textbf{Объект} & \textbf{$X_1$} & \textbf{$X_2$} & \textbf{\dots} & \textbf{$X_n$} & \textbf{Классы} \\ \hline
        		\endfirsthead
        		\hline
        		Объект & $X_1$ & $X_2$ & \dots & $X_n$ & Классы \\ \hline
        		\endhead
        		\hline
        		\multicolumn{4}{r}{продолжение на след. странице\ldots} \
        		\endfoot
        		\hline
        		\endlastfoot
        		    $\omega_1$ & $x_1(\omega_1)$ & $x_2(\omega_1)$ & \dots & $x_n(\omega_1)$ & $K_1$ \\
        		    $\omega_2$ & $x_1(\omega_2)$ & $x_2(\omega_2)$ & \dots & $x_n(\omega_2)$ & $K_i$ \\
        		    \dots & \dots & \dots & \dots & \dots & \dots\\
        		    $\omega_{r_m}$ & $x_1(\omega_{r_m})$ & $x_2(\omega_{r_m})$ & \dots & $x_n(\omega_{r_m})$ & $K_m$
        		\end{longtable}
        		
    	        Разбиение рассматриваемого множества объектов на классы
    	        $K_i$ может быть задано тремя способами. 
    	        \begin{itemize}
    		        \item Перечисление
    		            
    		            Каждый класс задается путём прямого указания его членов. Этот подход оправдан, когда доступна полная априорная информация обо всех объектах распознавания. Предъявляемые системе образы сравниваются с заданными описаниями представителей класса и относятся к тому классу, к которому они наиболее сходны.
    			    \item Задание общих свойств
    			    
    			        Класс задается описанием некоторых признаков, присущих всем его членам. 
    			    \item Кластеризация
    			        \begin{figure}[h!]
                            \centering \includegraphics[scale=0.5]{Materials/e.png}
                        \end{figure}
                        
    			        Если объект можно описать вектором признаков 
    			        или измерений, класс рассматривается как кластер. Тогда распознавание производится на основании рассчета расстояния от данного объекта до каждого кластера. 
    			        
    		    \end{itemize}
        		
    	    \subsubsection{Обучение без учителя}
    	        Не требуется запоминание классов объектов и последующего описания к ним поступающих образов. Достаточно лишь определения, относятся ли представленные объекты данному или различным классам. Поэтому при обучении системе представляется выборка из объектов с указанием, какие различны, а какие сходны. Не важно, какие значения будет вырабатывать решающая функция. Важно, чтобы для разнотипных объектов эти значения были разные, а для однотипных - одинаковые. 
    	        То есть, отсутствуют подсказки правильных ответов учителя.
        \subsection{Характеризация задач распознавания образов}
            Разнообразие задач распознавания образов можно охарактеризовать тремя параметрами
            
	        \subsubsection{Характеризация за способом, которым предъявляется наблюдателю обучающее множество}
	            \begin{itemize}
			        \item распознавание образов, основанное на     фиксированной выборке
			            
			            Несколько объектов из известных классов предъявляются системе (выборка). На основе выборки система вырабатывает решающие правила. Эти правила далее не меняются, даже при ошибке классификации.
				    \item распознавание образов, основанное на     последовательности выборки
				    
				        После первой выработки система применяет полученное правило, оценивает результат, модифицирует правило, если нужно, и процесс повторяется, пока результат не будет удовлетворённым. Этот подход называют адаптивным распознаванием (или машинным обучением).
				        
				        Здесь должны учитываться следующие свойства:
				        \begin{itemize}
    				        \item сходимость(изменение правил классификации должно приводить через конечное число корректировок к окончательному результату)
    					    \item вычисл. сложность(лёгкость)(финальное правило классификации должно минимизировать кол-во шагов, необходимых для распознавания)
    					    \item оптимальность (минимизация возможных ошибок)
    				    \end{itemize}
			    \end{itemize}
		    \subsubsection{Характеризация за типом правила классификации образов, которое строит системы распознавания}
		        \begin{itemize}
			        \item параллельные правила
			        
				        Производится ряд тестов над всей совокупностью выявленных данных об объекте. Например, если объект описан с помощью вектора, то оценка производится над всеми компонентами этого вектора, после чего делается предположение о принадлежности объекта образу. 
				        
				        Достоинство: надёжность, постоянное время, равное времени выполнения самой долгой из процедур оценивания. 
				        
				        Например, в объекте $\omega_1(x_1, x_2, x_3)$ время выполнения процедур $t(x_1) = 1 ns$, $t(x_2) = 5 ns$, $t(x_3) = 2 ns$. Тогда общее время $t(\omega_1) = max(t(x_1), t(x_2) t(x_3)) = 5 ns$ 
				    \item последовательные правила
				    
				        Сначала проверяется некоторое подмножество компонент вектора. На основе результата либо выбирается следующее множество для проверки, либо выносится результат распознавания.
				        
				        Недостатки: длительное время, равное сумме времен всех процедур, алгоритм может пойти по неверному пути.
			    \end{itemize}
		    \subsubsection{Характеризация за видом описания классифицируемых объектов} 
		        \begin{itemize}
			        \item эвлидово пространство описаний
			        
			            Когда объект можно считать набором результатов измерений. Применим для большинства физических шкал, неприменим для шкалы порядка.
				    \item списки признаков (цвет, пол \dots)
				    
				        Выявление качественных характеристик объекта и построение характеризирующего вектора.
				    \item структурное описание 
				        
				        Выделяются взаимоотношения между компонентами объекта.
			    \end{itemize}
		    
	    
\end{document}
